# ğŸ§  What Are Runnables in LangChain?

In LangChain, **Runnables** are the **core building blocks** used to execute **any operation in a pipeline** â€” whether thatâ€™s calling an LLM, transforming input, parsing output, or chaining multiple steps together.

They form the **foundation of LangChain Expression Language (LCEL)** â€” a simple, composable way to build and connect LLM applications.

---

## âš™ï¸ Intuition

Think of a `Runnable` as a  **function with superpowers** .

ğŸ§© It can:

* Take an **input** (e.g., user prompt)
* Do **some work** (call an LLM, retrieve data, or transform text)
* Return an **output**
* Be **connected** to other runnables to form a chain
* Be executed  **synchronously** ,  **asynchronously** , or **streamed**

---

## ğŸ—ï¸ Core Interface

All Runnables share a common interface:

```python
runnable.invoke(input)       # Run once synchronously
await runnable.ainvoke(input)  # Run once asynchronously
runnable.batch(inputs)       # Run on a list of inputs
runnable.stream(input)       # Stream partial outputs

```

This means no matter what kind of runnable it is (LLM, prompt, parser, chain), you can call it in the same way.

---

## ğŸ§© Common Runnables in LangChain

| Runnable Type                 | Description                                  | Example                                 |
| ----------------------------- | -------------------------------------------- | --------------------------------------- |
| **RunnableLambda**      | Custom Python function wrapped as a runnable | Transform or preprocess text            |
| **RunnableSequence**    | Chain multiple runnables sequentially        | Prompt â†’ LLM â†’ OutputParser           |
| **RunnableParallel**    | Run multiple runnables at the same time      | Query multiple LLMs or tools            |
| **RunnableMap**         | Map a runnable over dictionary fields        | Run different steps on different keys   |
| **RunnablePassthrough** | Pass input directly to next step             | Used when chaining without modification |

---

## ğŸ§  Example: Basic Runnable Chain

Letâ€™s create a simple chain:

**User prompt â†’ Format into template â†’ Call LLM â†’ Parse output**

```python
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnableSequence

# Step 1: Create components
prompt = PromptTemplate.from_template("Explain the concept of {topic} in simple terms.")
llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

# Step 2: Combine them into a chain (RunnableSequence)
chain = RunnableSequence(steps=[prompt, llm, parser])

# Step 3: Run it
result = chain.invoke({"topic": "quantum computing"})
print(result)

```

ğŸ§© Behind the scenes:

1. Input `{"topic": "quantum computing"}` â†’ passed into `PromptTemplate`
2. Prompt text â†’ passed into `ChatOpenAI`
3. LLM response â†’ passed into `StrOutputParser`
4. Parsed string â†’ final output âœ…

---

## âš¡ï¸ Runnables Are Composable

You can combine runnables easily using the  **pipe (`|`) operator** :

```python
chain = prompt | llm | parser

```

This is **syntactic sugar** for a `RunnableSequence`.

---

## ğŸ§© Example: RunnableLambda (Custom Logic)

```python
from langchain.schema.runnable import RunnableLambda

# A custom Python function wrapped as a Runnable
reverse_text = RunnableLambda(lambda x: x[::-1])

result = reverse_text.invoke("LangChain")
print(result)  # "niahCgnaL"

```

You can mix this with LLMs or prompts in a pipeline:

```python
chain = reverse_text | llm | parser

```

---

## âš™ï¸ RunnableParallel (Run in Parallel)

Example:

```python
from langchain.schema.runnable import RunnableParallel

parallel = RunnableParallel({
    "explanation": llm,
    "summary": llm
})

result = parallel.invoke("What is LangChain?")
print(result)

```

This runs both sub-runnables **simultaneously** and returns a dictionary:

```python
{
  "explanation": "...full explanation...",
  "summary": "...short summary..."
}

```

---

## ğŸ”¥ Why Runnables Are Powerful

âœ… **Unified interface** â€” Everything (LLMs, tools, retrievers, custom logic) uses the same `.invoke()` method.

âœ… **Composability** â€” You can build reusable modular pipelines.

âœ… **Streaming support** â€” Stream tokens as theyâ€™re generated.

âœ… **Async support** â€” Ideal for web apps or chatbots.

âœ… **Scalable** â€” You can parallelize or batch inputs easily.

---

## ğŸ“˜ Official and Readable Resources

* [Runnable Interface â€“ LangChain Documentation](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html?utm_source=chatgpt.com) â€” the API reference for the base Runnable class. [LangChain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html?utm_source=chatgpt.com)
* [LangChain Expression Language (LCEL) â€“ Official Guide](https://python.langchain.com/docs/concepts/lcel/?utm_source=chatgpt.com) â€” overview of LCEL, composition with Runnables. [LangChain](https://python.langchain.com/docs/concepts/lcel/?utm_source=chatgpt.com)
* [Runnable Interface â€“ Concepts Guide](https://python.langchain.com/docs/concepts/runnables/?utm_source=chatgpt.com) â€” conceptual explanation of Runnables, batching, streaming, etc. [LangChain](https://python.langchain.com/docs/concepts/runnables/?utm_source=chatgpt.com)
* [LCEL Cheatsheet â€“ How-To Guide](https://python.langchain.com/docs/how_to/lcel_cheatsheet/?utm_source=chatgpt.com) â€” quick reference for pipe (`|`), `RunnableSequence`, `RunnableParallel`. [LangChain](https://python.langchain.com/docs/how_to/lcel_cheatsheet/?utm_source=chatgpt.com)
* [â€œLangChain Expression Language Explainedâ€ â€“ Pinecone Tutorial](https://www.pinecone.io/learn/series/langchain/langchain-expression-language/?utm_source=chatgpt.com) â€” community explainer with examples. [pinecone.io](https://www.pinecone.io/learn/series/langchain/langchain-expression-language/?utm_source=chatgpt.com)
* [â€œUnderstanding LangChain Runnablesâ€ â€“ Mirascope Blog](https://mirascope.com/blog/langchain-runnables?utm_source=chatgpt.com) â€” another independent take on Runnables.
